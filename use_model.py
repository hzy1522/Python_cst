"""
è´´ç‰‡å¤©çº¿è®¾è®¡ç³»ç»Ÿ - æ¨¡å‹ä½¿ç”¨æ¨¡å—
Patch Antenna Design System - Model Usage Module
"""

import sys
import os
import numpy as np
import torch
import pandas as pd


# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from patch_antenna_design import PatchAntennaDesignSystem
    from python_hfss import calculate_from_hfss as calculate_from_hfss_py
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def get_device():
    """è‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡ï¼ˆä¼˜å…ˆGPUï¼Œæ²¡æœ‰åˆ™ç”¨CPUï¼‰"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device("cpu")
        print(f"â„¹ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUæ¨ç†")
    return device

def use_trained_gan_model(model_info_path='models/trained_gan_model_info.npy',
                         target_performances=None,
                         gan_generator_path='models/gan_generator.pth',
                         forward_gan_generator_path='models/forward_gan_generator.pth'):
    """
    ä½¿ç”¨å·²è®­ç»ƒçš„GANæ¨¡å‹ç”Ÿæˆå¤©çº¿è®¾è®¡

    Args:
        model_info_path: æ¨¡å‹ä¿¡æ¯æ–‡ä»¶è·¯å¾„
        target_performances: ç›®æ ‡æ€§èƒ½å‚æ•°åˆ—è¡¨
    """
    print("\n" + "=" * 70)
    print("ä½¿ç”¨å·²è®­ç»ƒçš„GANæ¨¡å‹")
    print("=" * 70)

    device = get_device()
    system = PatchAntennaDesignSystem()

    # 1. åŠ è½½è®­ç»ƒä¿¡æ¯å’Œæ¨¡å‹çŠ¶æ€
    print(f"\n1. åŠ è½½è®­ç»ƒä¿¡æ¯ä» {model_info_path}...")
    if os.path.exists(model_info_path):
        training_info = np.load(model_info_path, allow_pickle=True).item()
        # åŠ è½½é¢„å¤„ç†å™¨çŠ¶æ€
        print(f"âœ… è®­ç»ƒä¿¡æ¯åŠ è½½å®Œæˆï¼")
        print(f"   è®­ç»ƒæ—¶é—´: {training_info.get('timestamp', 'æœªçŸ¥')}")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {training_info.get('data_samples', 'æœªçŸ¥')}")
        print(f"   è®­ç»ƒè®¾å¤‡: {training_info.get('device', 'æœªçŸ¥')}")

        if 'scalers' in training_info:
            # é‡å»º input_scaler (system.scaler) - StandardScaler
            from sklearn.preprocessing import StandardScaler, MinMaxScaler
            system.scaler = StandardScaler()
            input_scaler_data = training_info['scalers']['input_scaler']
            system.scaler.scale_ = input_scaler_data['scale_']
            system.scaler.mean_ = input_scaler_data['mean_']
            system.scaler.var_ = input_scaler_data['var_']
            if 'n_features_in_' in input_scaler_data and input_scaler_data['n_features_in_'] is not None:
                system.scaler.n_features_in_ = input_scaler_data['n_features_in_']
            else:
                system.scaler.n_features_in_ = len(input_scaler_data['scale_']) if 'scale_' in input_scaler_data else 0
            if 'n_samples_seen_' in input_scaler_data and input_scaler_data['n_samples_seen_'] is not None:
                system.scaler.n_samples_seen_ = input_scaler_data['n_samples_seen_']
            else:
                system.scaler.n_samples_seen_ = 1

            # é‡å»º target_scaler - MinMaxScaler
            system.target_scaler = MinMaxScaler()
            target_scaler_data = training_info['scalers']['target_scaler']
            system.target_scaler.scale_ = target_scaler_data['scale_']
            system.target_scaler.min_ = target_scaler_data['min_']
            system.target_scaler.data_min_ = target_scaler_data['data_min_']
            system.target_scaler.data_max_ = target_scaler_data['data_max_']
            system.target_scaler.data_range_ = target_scaler_data['data_range_']
            if 'n_features_in_' in target_scaler_data and target_scaler_data['n_features_in_'] is not None:
                system.target_scaler.n_features_in_ = target_scaler_data['n_features_in_']
            else:
                system.target_scaler.n_features_in_ = len(target_scaler_data['scale_']) if 'scale_' in target_scaler_data else 0
            if 'n_samples_seen_' in target_scaler_data and target_scaler_data['n_samples_seen_'] is not None:
                system.target_scaler.n_samples_seen_ = target_scaler_data['n_samples_seen_']
            else:
                system.target_scaler.n_samples_seen_ = 1

            # æ›´æ–°æ£€æŸ¥å‡½æ•°ä»¥é€‚é…ä¸åŒç±»å‹çš„ç¼©æ”¾å™¨
            def _check_scalers_ready(system):
                """æ£€æŸ¥é¢„å¤„ç†å™¨æ˜¯å¦å·²å°±ç»ª"""
                try:
                    # æ£€æŸ¥ scaler (StandardScaler) æ˜¯å¦å·²æ‹Ÿåˆ
                    _ = system.scaler.scale_
                    _ = system.scaler.mean_

                    # æ£€æŸ¥ target_scaler (MinMaxScaler) æ˜¯å¦å·²æ‹Ÿåˆ
                    _ = system.target_scaler.scale_
                    _ = system.target_scaler.min_

                    return True
                except AttributeError:
                    return False

    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒä¿¡æ¯æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        training_info = {}

    # 2. å®šä¹‰è®¾è®¡ç›®æ ‡
    if target_performances is None:
        target_performances = [
            [-35.0, 2.45, 7.0],   # WiFi 2.45GHz é«˜æ€§èƒ½è®¾è®¡
            [-30.0, 2.4, 6.5],    # WiFi 2.4GHz æ ‡å‡†è®¾è®¡
            [-25.0, 2.5, 6.0],    # ä½æˆæœ¬è®¾è®¡
            [-40.0, 2.42, 7.5]    # è¶…é«˜æ€§èƒ½è®¾è®¡
        ]
    # åŠ è½½æ¨¡å‹
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if system.generator is None:
        try:
            system.create_gan_models()
            state_dict = torch.load(gan_generator_path, map_location=system.device)
            system.generator.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„åå‘GANç”Ÿæˆå™¨")
        except Exception as e:
            print(f"åŠ è½½åå‘GANæ¨¡å‹å¤±è´¥: {e}")

    if system.forward_generator is None:
        try:
            system.create_forward_gan_models()
            state_dict = torch.load(forward_gan_generator_path, map_location=system.device)
            system.forward_generator.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„æ­£å‘GANç”Ÿæˆå™¨")
        except Exception as e:
            print(f"åŠ è½½æ­£å‘GANæ¨¡å‹å¤±è´¥: {e}")

    if system.performance_predictor is None:
        try:
            system.performance_predictor = system.create_performance_predictor()
            state_dict = torch.load('best_performance_predictor.pth', map_location=system.device)
            system.performance_predictor.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„æ€§èƒ½é¢„æµ‹å™¨")
        except Exception as e:
            print(f"åŠ è½½æ€§èƒ½é¢„æµ‹å™¨å¤±è´¥: {e}")

    # 3. ä½¿ç”¨GANç”Ÿæˆå¤©çº¿è®¾è®¡
    print(f"\n2. ä½¿ç”¨GANç”Ÿæˆå¤©çº¿è®¾è®¡...")
    try:
        generated_designs, generated_performances = system.generate_antenna_designs(
            target_performances, num_samples=20
        )
        # æ·»åŠ ç©ºçš„historyå­—å…¸ç”¨äºå¯è§†åŒ–
        history = {
            'generator_loss': [],
            'discriminator_loss': [],
            'adversarial_loss': [],
            'performance_loss': []
        }
        # å¯è§†åŒ–ç”Ÿæˆç»“æœ
        system.visualize_gan_results(history, generated_designs, generated_performances)

    except Exception as e:
        print(f"âŒ GANç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
        print("ğŸ’¡ è¯·ç¡®è®¤æ¨¡å‹æ–‡ä»¶å’Œé¢„å¤„ç†å™¨çŠ¶æ€æ˜¯å¦å®Œæ•´ä¿å­˜")
        return None

    # 4. ä¿å­˜ç”Ÿæˆçš„è®¾è®¡
    design_df = pd.DataFrame({
        'patch_length': generated_designs[:, 0],
        'patch_width': generated_designs[:, 1],
        's11_min': generated_performances[:, 0],
        'freq_at_s11_min': generated_performances[:, 1],
        'far_field_gain': generated_performances[:, 2]
    })

    # åˆ›å»ºç»“æœç›®å½•
    if not os.path.exists('results'):
        os.makedirs('results')

    design_csv_path = 'results/gan_generated_designs.csv'
    design_df.to_csv(design_csv_path, index=False)
    print(f"ç”Ÿæˆçš„å¤©çº¿è®¾è®¡å·²ä¿å­˜åˆ° {design_csv_path}")

def use_trained_gan_model_prediction_results(model_info_path='models/trained_gan_model_info.npy',
                         patch_lengths=None,
                         patch_widths=None,
                         gan_generator_path='models/gan_generator.pth',
                         forward_gan_generator_path='models/forward_gan_generator.pth'):
    """
    ä½¿ç”¨å·²è®­ç»ƒçš„GANæ¨¡å‹ç”Ÿæˆå¤©çº¿è®¾è®¡

    Args:
        model_info_path: æ¨¡å‹ä¿¡æ¯æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 70)
    print("ä½¿ç”¨å·²è®­ç»ƒçš„GANæ¨¡å‹")
    print("=" * 70)

    device = get_device()
    system = PatchAntennaDesignSystem()

    # 1. åŠ è½½è®­ç»ƒä¿¡æ¯å’Œæ¨¡å‹çŠ¶æ€
    print(f"\n1. åŠ è½½è®­ç»ƒä¿¡æ¯ä» {model_info_path}...")
    if os.path.exists(model_info_path):
        training_info = np.load(model_info_path, allow_pickle=True).item()
        # åŠ è½½é¢„å¤„ç†å™¨çŠ¶æ€
        print(f"âœ… è®­ç»ƒä¿¡æ¯åŠ è½½å®Œæˆï¼")
        print(f"   è®­ç»ƒæ—¶é—´: {training_info.get('timestamp', 'æœªçŸ¥')}")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {training_info.get('data_samples', 'æœªçŸ¥')}")
        print(f"   è®­ç»ƒè®¾å¤‡: {training_info.get('device', 'æœªçŸ¥')}")

        if 'scalers' in training_info:
            # é‡å»º input_scaler (system.scaler) - StandardScaler
            from sklearn.preprocessing import StandardScaler, MinMaxScaler
            system.scaler = StandardScaler()
            input_scaler_data = training_info['scalers']['input_scaler']
            system.scaler.scale_ = input_scaler_data['scale_']
            system.scaler.mean_ = input_scaler_data['mean_']
            system.scaler.var_ = input_scaler_data['var_']
            if 'n_features_in_' in input_scaler_data and input_scaler_data['n_features_in_'] is not None:
                system.scaler.n_features_in_ = input_scaler_data['n_features_in_']
            else:
                system.scaler.n_features_in_ = len(input_scaler_data['scale_']) if 'scale_' in input_scaler_data else 0
            if 'n_samples_seen_' in input_scaler_data and input_scaler_data['n_samples_seen_'] is not None:
                system.scaler.n_samples_seen_ = input_scaler_data['n_samples_seen_']
            else:
                system.scaler.n_samples_seen_ = 1

            # é‡å»º target_scaler - MinMaxScaler
            system.target_scaler = MinMaxScaler()
            target_scaler_data = training_info['scalers']['target_scaler']
            system.target_scaler.scale_ = target_scaler_data['scale_']
            system.target_scaler.min_ = target_scaler_data['min_']
            system.target_scaler.data_min_ = target_scaler_data['data_min_']
            system.target_scaler.data_max_ = target_scaler_data['data_max_']
            system.target_scaler.data_range_ = target_scaler_data['data_range_']
            if 'n_features_in_' in target_scaler_data and target_scaler_data['n_features_in_'] is not None:
                system.target_scaler.n_features_in_ = target_scaler_data['n_features_in_']
            else:
                system.target_scaler.n_features_in_ = len(target_scaler_data['scale_']) if 'scale_' in target_scaler_data else 0
            if 'n_samples_seen_' in target_scaler_data and target_scaler_data['n_samples_seen_'] is not None:
                system.target_scaler.n_samples_seen_ = target_scaler_data['n_samples_seen_']
            else:
                system.target_scaler.n_samples_seen_ = 1

            # æ›´æ–°æ£€æŸ¥å‡½æ•°ä»¥é€‚é…ä¸åŒç±»å‹çš„ç¼©æ”¾å™¨
            def _check_scalers_ready(system):
                """æ£€æŸ¥é¢„å¤„ç†å™¨æ˜¯å¦å·²å°±ç»ª"""
                try:
                    # æ£€æŸ¥ scaler (StandardScaler) æ˜¯å¦å·²æ‹Ÿåˆ
                    _ = system.scaler.scale_
                    _ = system.scaler.mean_

                    # æ£€æŸ¥ target_scaler (MinMaxScaler) æ˜¯å¦å·²æ‹Ÿåˆ
                    _ = system.target_scaler.scale_
                    _ = system.target_scaler.min_

                    return True
                except AttributeError:
                    return False

    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒä¿¡æ¯æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        training_info = {}

    # åŠ è½½æ¨¡å‹
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if system.generator is None:
        try:
            system.create_gan_models()
            state_dict = torch.load(gan_generator_path, map_location=system.device)
            system.generator.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„åå‘GANç”Ÿæˆå™¨")
        except Exception as e:
            print(f"åŠ è½½åå‘GANæ¨¡å‹å¤±è´¥: {e}")

    if system.forward_generator is None:
        try:
            system.create_forward_gan_models()
            state_dict = torch.load(forward_gan_generator_path, map_location=system.device)
            system.forward_generator.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„æ­£å‘GANç”Ÿæˆå™¨")
        except Exception as e:
            print(f"åŠ è½½æ­£å‘GANæ¨¡å‹å¤±è´¥: {e}")

    if system.performance_predictor is None:
        try:
            system.performance_predictor = system.create_performance_predictor()
            state_dict = torch.load('best_performance_predictor.pth', map_location=system.device)
            system.performance_predictor.load_state_dict(state_dict)
            print("æˆåŠŸåŠ è½½é¢„è®­ç»ƒçš„æ€§èƒ½é¢„æµ‹å™¨")
        except Exception as e:
            print(f"åŠ è½½æ€§èƒ½é¢„æµ‹å™¨å¤±è´¥: {e}")

    hfss_results = []

    if patch_lengths is None or patch_widths is None:
        gan_data = pd.read_csv('results/gan_generated_designs.csv')
        patch_lengths = gan_data['patch_length'].values
        patch_widths = gan_data['patch_width'].values
        print(f"ä»GANç”Ÿæˆç»“æœä¸­è¯»å–äº† {len(patch_lengths)} è¡Œæ•°æ®")
    else:
        # ç¡®ä¿å•ä¸ªå€¼ä¹Ÿè¢«è½¬æ¢ä¸ºæ•°ç»„å½¢å¼
        if not isinstance(patch_lengths, (list, np.ndarray)):
            patch_lengths = [patch_lengths]
        if not isinstance(patch_widths, (list, np.ndarray)):
            patch_widths = [patch_widths]
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        patch_lengths = np.array(patch_lengths)
        patch_widths = np.array(patch_widths)

    # 5. ä½¿ç”¨HFSSè®¡ç®—æ‰€æœ‰ç”Ÿæˆå¤©çº¿çš„æ€§èƒ½ç»“æœ
    print(f"\n3. ä½¿ç”¨HFSSéªŒè¯æ‰€æœ‰ç”Ÿæˆçš„å¤©çº¿è®¾è®¡...")

    for i in range(len(patch_lengths)):
        design = np.zeros(2)  # åˆå§‹åŒ–designæ•°ç»„
        design[0] = patch_lengths[i]
        design[1] = patch_widths[i]
        print(f"\néªŒè¯è®¾è®¡ {i + 1}/{len(patch_lengths)}: é•¿åº¦={design[0]:.2f}mm, å®½åº¦={design[1]:.2f}mm")

        # HFSSä»¿çœŸå‚æ•°è®¾ç½®
        antenna_params = {
            "unit": "GHz",
            "patch_length": float(design[0]),
            "patch_width": float(design[1]),
            "patch_name": "Patch",
            "freq_step": "0.01GHz",
            "num_of_freq_points": 201,
            "start_frequency": 2,
            "stop_frequency": 3,
            "center_frequency": 2.5,
            "sweep_type": "Interpolating",
            "sub_length": 50,
            "sub_width": 60,
            "sub_high": 1.575,
            "feed_r1": 0.5,
            "feed_h": 1.575,
            "feed_center": 6.3,
            "lumpedport_r": 1.5,
            "lumpedport_D": 2.3 / 2,
        }
        # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        if system.forward_generator is not None:
            system.forward_generator.eval()
        if system.performance_predictor is not None:
            system.performance_predictor.eval()

        # s11_curve_predict, s11_min_predict, freq_at_s11_min_predict, far_field_gain_predict = system.predict_s11_from_dimensions(
        #     design[0], design[1])
        s11_curve_predict = system.predict_s11_from_dimensions(design[0], design[1])
        # è°ƒç”¨HFSSè®¡ç®—
        train_model = False
        try:
            success, freq_at_s11_min, far_field_gain, s11_min, output_file = calculate_from_hfss_py(
                antenna_params, train_model
            )

            if success and output_file:
                print(f"  HFSSè®¡ç®—æˆåŠŸ!")
                print(f"  å®é™…æ€§èƒ½: S11={s11_min:.2f}dB, é¢‘ç‡={freq_at_s11_min:.2f}GHz, å¢ç›Š={far_field_gain:.2f}dBi")
                # print(f"  æ¨¡å‹é¢„æµ‹æ€§èƒ½: S11={s11_min_predict:.2f}dB, é¢‘ç‡={freq_at_s11_min_predict:.2f}GHz, å¢ç›Š={far_field_gain_predict:.2f}dBi")

                # ä¿å­˜ç»“æœ
                hfss_results.append({
                    'design_index': i,
                    'patch_length': design[0],
                    'patch_width': design[1],
                    # 'predicted_s11': s11_min_predict,
                    # 'predicted_freq': freq_at_s11_min_predict,
                    # 'predicted_gain': far_field_gain_predict,
                    'actual_s11': s11_min,
                    'actual_freq': freq_at_s11_min,
                    'actual_gain': far_field_gain,
                    'output_file': output_file
                })

                # ç»˜åˆ¶S11å¯¹æ¯”å›¾
                system.plot_s11_comparison_advanced(
                    float(design[0]), float(design[1]),
                    output_file, frequency_column=0, s11_column=1,
                    predict_s11_curve=s11_curve_predict
                )
            else:
                print(f"  HFSSè®¡ç®—å¤±è´¥")
                hfss_results.append({
                    'design_index': i,
                    'patch_length': design[0],
                    'patch_width': design[1],
                    # 'predicted_s11': s11_min_predict,
                    # 'predicted_freq': freq_at_s11_min_predict,
                    # 'predicted_gain': far_field_gain_predict,
                    'actual_s11': None,
                    'actual_freq': None,
                    'actual_gain': None,
                    'output_file': None
                })
        except Exception as e:
            print(f"  HFSSè®¡ç®—å‡ºé”™: {e}")
            hfss_results.append({
                'design_index': i,
                'patch_length': design[0],
                'patch_width': design[1],
                # 'predicted_s11': s11_min_predict,
                # 'predicted_freq': freq_at_s11_min_predict,
                # 'predicted_gain': far_field_gain_predict,
                'actual_s11': None,
                'actual_freq': None,
                'actual_gain': None,
                'output_file': None
            })

    # 6. ä¿å­˜HFSSéªŒè¯ç»“æœ
    if hfss_results:
        hfss_df = pd.DataFrame(hfss_results)
        hfss_csv_path = 'results/hfss_validation_results.csv'
        hfss_df.to_csv(hfss_csv_path, index=False)
        print(f"\nHFSSéªŒè¯ç»“æœå·²ä¿å­˜åˆ° {hfss_csv_path}")

def load_target_specs_from_csv(csv_file_path):
    """
    ä»CSVæ–‡ä»¶è¯»å–Så‚æ•°æœ€å°å€¼ã€å¢ç›Šã€é¢‘ç‡ä»¥åŠ201ä¸ªSå‚æ•°ç‚¹ï¼Œä¿å­˜æˆtarget_specsæ ¼å¼

    Args:
        csv_file_path: CSVæ–‡ä»¶è·¯å¾„

    Returns:
        target_specs: 204ç»´çš„ç›®æ ‡æ€§èƒ½å‚æ•°åˆ—è¡¨
    """
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_file_path)

    target_specs = []

    # éå†æ¯ä¸€è¡Œæ•°æ®
    for index, row in df.iterrows():
        # æå–ä¸»è¦æ€§èƒ½æŒ‡æ ‡
        s11_min = row['_æœ€å°å€¼']  # S11æœ€å°å€¼
        freq = row['Freq [GHz]']  # å¯¹åº”é¢‘ç‡
        gain = row['Gain_dB']   # è¿œåŒºåœºå¢ç›Š

        # æå–201ä¸ªSå‚æ•°ç‚¹
        # æ–¹æ³•1: å¦‚æœåˆ—åæ˜¯é¢‘ç‡å€¼ï¼ˆå¦‚2.000, 2.010, ...ï¼‰
        s_parameters = []
        freq_points = np.linspace(2.0, 3.0, 201)  # ç”Ÿæˆ201ä¸ªé¢‘ç‡ç‚¹
        for freq_point in freq_points:
            col_name = f"{freq_point:.3f}"  # æ ¹æ®å®é™…åˆ—åæ ¼å¼è°ƒæ•´
            if col_name in row:
                s_parameters.append(row[col_name])
            else:
                # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”åˆ—ï¼Œå¯ä»¥ä½¿ç”¨é»˜è®¤å€¼æˆ–æ’å€¼
                s_parameters.append(0.0)  # ä½¿ç”¨é»˜è®¤å€¼

        # æ–¹æ³•2: å¦‚æœSå‚æ•°æ˜¯è¿ç»­çš„åˆ—ï¼ˆå¦‚s11_1, s11_2, ..., s11_201ï¼‰
        # s_parameters = [row[f's11_{i}'] for i in range(1, 202)]

        # æ„é€ 204ç»´å‘é‡ï¼š[S11æœ€å°å€¼, å¯¹åº”é¢‘ç‡, è¿œåŒºåœºå¢ç›Š, 201ä¸ªSå‚æ•°ç‚¹]
        # target_spec = [s11_min, freq, gain] + s_parameters
        target_spec = s_parameters
        target_specs.append(target_spec)

    return target_specs


if __name__ == "__main__":
    print("è´´ç‰‡å¤©çº¿GANæ¨¡å‹ä½¿ç”¨ç³»ç»Ÿ")
    print("=" * 70)

    # ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹
    model_info_path = 'models/trained_gan_model_info.npy'


    # å¯ä»¥è‡ªå®šä¹‰ç›®æ ‡æ€§èƒ½
    # target_specs = [
    #     [-15.0, 2.5, 5.0],  # WiFi 2.45GHz é«˜æ€§èƒ½è®¾è®¡
    # ]

    target_specs = load_target_specs_from_csv('TEST_RESULT/data_dict_pandas_20251117_154108.csv')
    use_trained_gan_model(model_info_path, target_specs)

    use_trained_gan_model_prediction_results()
    # use_trained_gan_model_prediction_results(patch_lengths='40', patch_widths='50')

    print("\n" + "=" * 70)
    print("æ¨¡å‹ä½¿ç”¨å®Œæˆï¼")
    print("=" * 70)
    print("\næ‚¨å¯ä»¥åœ¨ results ç›®å½•ä¸­æŸ¥çœ‹ç”Ÿæˆçš„è®¾è®¡ç»“æœã€‚")
