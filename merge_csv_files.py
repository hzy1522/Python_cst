"""
CSVæ–‡ä»¶åˆå¹¶å·¥å…· - ç®€æ´ç‰ˆ
è§£å†³ï¼šåªå¤„ç†äº†ä¸€ä¸ªæ–‡ä»¶çš„é—®é¢˜
"""

import os
import csv
import glob
import chardet

def detect_file_encoding(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç """
    with open(file_path, 'rb') as f:
        result = chardet.detect(f.read(10000))
    return result['encoding'] or 'utf-8'

def merge_single_line_csv_files(input_pattern, output_file, header_check_count=40):
    """åˆå¹¶æ¯ä¸ªåªæœ‰ä¸€è¡Œè¡¨å¤´ä¸€è¡Œæ•°æ®çš„CSVæ–‡ä»¶"""
    print("=" * 60)
    print("CSVæ–‡ä»¶åˆå¹¶å·¥å…· - ç®€æ´ç‰ˆ")
    print(f"å¤„ç†æ¨¡å¼ï¼šä¸€è¡Œè¡¨å¤´ + ä¸€è¡Œæ•°æ® + å‰{header_check_count}åˆ—åŒ¹é…")
    print("ç­›é€‰è§„åˆ™ï¼šåˆ é™¤'_æœ€å°å€¼'åˆ—ä¸­æ•°å€¼ > -5dB çš„è¡Œ")
    print("=" * 60)

    # åˆ é™¤æ—§çš„è¾“å‡ºæ–‡ä»¶
    if os.path.exists(output_file):
        os.remove(output_file)

    # è·å–æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
    all_files = glob.glob(input_pattern)
    if not all_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é… '{input_pattern}' çš„æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")

    # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„è¡¨å¤´ä½œä¸ºæ ‡å‡†
    first_file = all_files[0]
    file_encoding = detect_file_encoding(first_file)
    print(f"ğŸ” ä½¿ç”¨ '{os.path.basename(first_file)}' ä½œä¸ºæ ‡å‡†æ¨¡æ¿")

    try:
        with open(first_file, 'r', encoding=file_encoding) as f:
            reader = csv.reader(f)
            lines = []
            for line in reader:
                stripped_line = [col.strip() for col in line]
                if any(stripped_line):
                    lines.append(line)

            if len(lines) < 2:
                print(f"âŒ ç¬¬ä¸€ä¸ªæ–‡ä»¶è¡Œæ•°ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘2è¡Œï¼‰")
                return

            header = lines[0]
            if len(header) < header_check_count:
                print(f"âŒ è¡¨å¤´åˆ—æ•°ä¸è¶³{header_check_count}åˆ—")
                return

            print(f"ğŸ“‹ æ ‡å‡†è¡¨å¤´ï¼š{len(header)}åˆ—ï¼Œå‰{header_check_count}åˆ—ä¸ºåŒ¹é…åŸºå‡†")

    except Exception as e:
        print(f"âŒ è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤±è´¥: {e}")
        return

    # å†™å…¥è¡¨å¤´
    try:
        with open(output_file, 'w', encoding='utf-8-sig', newline='') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
        print(f"âœ“ è¡¨å¤´å†™å…¥æˆåŠŸ")

    except Exception as e:
        print(f"âŒ è¡¨å¤´å†™å…¥å¤±è´¥: {e}")
        return

    # å¼€å§‹åˆå¹¶æ•°æ®
    total_rows = 0
    skipped_files = []
    success_files = []

    print(f"\nğŸš€ å¼€å§‹åˆå¹¶æ•°æ®...")
    print("-" * 60)

    for i, file in enumerate(all_files):
        file_basename = os.path.basename(file)

        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡ï¼‰
        if i % 10 == 0 or i == len(all_files) - 1:
            print(f"è¿›åº¦: {i+1}/{len(all_files)} æ–‡ä»¶", end='\r')

        try:
            file_encoding = detect_file_encoding(file)
            with open(file, 'r', encoding=file_encoding) as f:
                reader = csv.reader(f)
                lines = []
                for line in reader:
                    stripped_line = [col.strip() for col in line]
                    if any(stripped_line):
                        lines.append(line)

            # æ£€æŸ¥æ–‡ä»¶ç»“æ„
            if len(lines) < 2:
                skipped_files.append((file_basename, "è¡Œæ•°ä¸è¶³"))
                continue

            # æ£€æŸ¥è¡¨å¤´å‰Nåˆ—
            file_header = lines[0]
            standard_header_slice = [col.strip() for col in header[:header_check_count]]
            file_header_slice = [col.strip() for col in file_header[:header_check_count]]

            if file_header_slice != standard_header_slice:
                skipped_files.append((file_basename, "è¡¨å¤´ä¸åŒ¹é…"))
                continue

            # æ£€æŸ¥æ•°æ®åˆ—æ•°
            data_line = lines[1]
            if len(data_line) < len(header):
                skipped_files.append((file_basename, "æ•°æ®åˆ—æ•°ä¸è¶³"))
                continue

            # å†™å…¥æ•°æ®
            with open(output_file, 'a', encoding='utf-8-sig', newline='') as outfile:
                writer = csv.writer(outfile)
                writer.writerow(data_line)

            total_rows += 1
            success_files.append(file_basename)

        except Exception as e:
            error_msg = str(e)[:50]
            skipped_files.append((file_basename, f"é”™è¯¯: {error_msg}"))

    # æ•°æ®æ¸…ç†æ­¥éª¤
    print(f"\n\nğŸ§¹ å¼€å§‹æ•°æ®ç­›é€‰...")

    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            all_lines = [line for line in reader if any(col.strip() for col in line)]

        if len(all_lines) > 1:
            header_row = all_lines[0]
            data_rows = all_lines[1:]

            # æ‰¾åˆ°"_æœ€å°å€¼"åˆ—
            min_value_col_index = -1
            for i, col_name in enumerate(header_row):
                if "_æœ€å°å€¼" in str(col_name):
                    min_value_col_index = i
                    break

            if min_value_col_index != -1:
                min_value_col_name = header_row[min_value_col_index]
                filtered_data = []
                removed_count = 0

                for row in data_rows:
                    try:
                        min_value = float(row[min_value_col_index])
                        if min_value <= -5.0:
                            filtered_data.append(row)
                        else:
                            removed_count += 1
                    except (ValueError, IndexError):
                        filtered_data.append(row)

                print(f"ğŸ“Š ç­›é€‰ç»Ÿè®¡:")
                print(f"   åŸå§‹æ•°æ®: {len(data_rows)} è¡Œ")
                print(f"   ç­›é€‰å: {len(filtered_data)} è¡Œ")
                print(f"   åˆ é™¤è¡Œæ•°: {removed_count} è¡Œ (S11 > -5dB)")

                # ä¿å­˜ç­›é€‰åçš„æ•°æ®
                with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow(header_row)
                    writer.writerows(filtered_data)

                print(f"âœ“ æ•°æ®ç­›é€‰å®Œæˆ")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°'_æœ€å°å€¼'åˆ—ï¼Œè·³è¿‡ç­›é€‰")
        else:
            print(f"âš ï¸  æ•°æ®ä¸è¶³ï¼Œè·³è¿‡ç­›é€‰")

    # è¾“å‡ºæ€»ç»“æŠ¥å‘Š
    print(f"\n" + "="*60)
    print("ğŸ“‹ åˆå¹¶å®ŒæˆæŠ¥å‘Š")
    print("="*60)
    print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {len(all_files)}")
    print(f"âœ… æˆåŠŸå¤„ç†: {len(success_files)} ä¸ªæ–‡ä»¶")
    print(f"âŒ è·³è¿‡æ–‡ä»¶: {len(skipped_files)} ä¸ªæ–‡ä»¶")

    if skipped_files:
        # ç»Ÿè®¡è·³è¿‡åŸå› 
        reason_stats = {}
        for file, reason in skipped_files:
            reason_stats[reason] = reason_stats.get(reason, 0) + 1

        print(f"\nğŸ” è·³è¿‡åŸå› ç»Ÿè®¡:")
        for reason, count in reason_stats.items():
            print(f"   â€¢ {reason}: {count} ä¸ªæ–‡ä»¶")

    # æœ€ç»ˆéªŒè¯
    if os.path.exists(output_file):
        file_size = os.path.getsize(output_file)
        with open(output_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            lines = [line for line in reader if any(col.strip() for col in line)]

        if len(lines) > 0:
            final_data_rows = len(lines) - 1
            print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            print(f"ğŸ“ˆ æœ€ç»ˆæ•°æ®: {final_data_rows} è¡Œ Ã— {len(lines[0])} åˆ—")
            print("âœ… åˆå¹¶ä»»åŠ¡å®Œæˆï¼")
        else:
            print(f"\nâŒ é”™è¯¯: è¾“å‡ºæ–‡ä»¶ä¸ºç©ºï¼")

    return output_file

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    input_pattern = "./RESULT/data_dict_pandas_*.csv"
    output_file = "merged_detailed_antenna_data.csv"
    header_check_count = 40

    # è¿è¡Œåˆå¹¶
    merge_single_line_csv_files(input_pattern, output_file, header_check_count)

if __name__ == "__main__":
    main()